"""
Project Overview Page - Comprehensive project description and deliverables
"""
import streamlit as st

def show():
    st.title("ğŸ“– FDA-3-Stream: Project Overview")
    st.markdown("---")
    
    # Header
    st.markdown("""
    ## Real-Time Quantitative Analysis of Revenue Recognition Practices
    **Group 16** | Kafka Ã— River Ã— CapyMOA
    
    ---
    """)
    
    # Overall Objective
    st.header("ğŸ¯ Overall Objective")
    st.markdown("""
    To develop a real-time streaming system that analyzes revenue recognition disclosures and financial metrics 
    from SEC 10-K filings to detect aggressive accounting or inconsistent revenue practices. The system integrates:
    - **Apache Kafka** for continuous data ingestion
    - **River (Python)** for online classification and regression
    - **CapyMOA** for drift-aware adaptive pattern detection
    """)
    
    # System Architecture
    st.header("ğŸ—ï¸ System Architecture Overview")
    st.markdown("""
    The architecture involves three core layers:
    1. **Data Ingestion** using Kafka
    2. **Real-time Model Updates** using River and CapyMOA
    3. **Explainable Dashboards** for visualization
    
    Producers stream textual and numeric data to Kafka, consumers process features in real time, and models adapt 
    dynamically to changes in revenue recognition styles.
    """)
    
    # Architecture Diagram
    st.subheader("Architecture Flow")
    st.code("""
    Data Source (CSV/EDGAR)
         â†“
    Kafka Producer (Module 1)
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                         â†“
    Text Stream          Numeric Stream
         â†“                         â†“
    River Consumers      CapyMOA Drift
    (Module 2)           (Module 3)
         â†“                         â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
         Fusion Consumer (Module 4)
                 â†“
         Alert Topic
                 â†“
         Dashboard (Module 6)
    """, language="text")
    
    # Modules
    st.header("ğŸ“¦ Integrated Functional Modules")
    
    modules = [
        {
            "title": "Module 1 â€” Streaming Extraction & Feature Generation",
            "description": "Extract 'Revenue Recognition' text from accounting policies of 10-K filings. Compute numeric ratios such as Revenue-to-CashFlow alignment ratio, Deferred Revenue/Total Revenue, and YoY Growth Rate variance. Stream these data points to Kafka topics.",
            "delivered": "âœ… Kafka Producer (`kafka_producer.py`) streams revenue data with computed ratios to Kafka topics"
        },
        {
            "title": "Module 2 â€” Real-Time Text Classification (River)",
            "description": "Train incremental classifiers (MultinomialNB, LogisticRegression, HoeffdingTreeClassifier) using River for adaptive revenue policy classification (Aggressive, Conservative, Neutral).",
            "delivered": "âœ… Enhanced Consumer implements all three classifiers with ensemble prediction and real-time metrics"
        },
        {
            "title": "Module 3 â€” Numeric Stream Regression & Drift Detection",
            "description": "Use River's AdaptiveRandomForestRegressor for financial ratio prediction and ADWIN for drift detection; apply CapyMOA DDM and EDDM to confirm anomalies.",
            "delivered": "âœ… Regression with AdaptiveRandomForest, 5 drift detectors (ADWIN, DDM, EDDM, KSWIN, PageHinkley)"
        },
        {
            "title": "Module 4 â€” Cross-Platform Anomaly Fusion",
            "description": "Fuse River and CapyMOA outputs in Kafka 'revenue_alerts' topic. Flag 'High-Risk Revenue Recognition' when both detectors signal drift within one quarter.",
            "delivered": "âœ… Fusion consumer combines multiple detector outputs and generates high-risk alerts"
        },
        {
            "title": "Module 5 â€” Explainable Streaming Analytics",
            "description": "Implement feature importance tracking with River (incremental SHAP) and CapyMOA's InformationGain evaluators to reveal linguistic or ratio-based anomaly drivers.",
            "delivered": "âœ… Feature importance tracking for text and numeric features, displayed on shutdown"
        },
        {
            "title": "Module 6 â€” Automated Revenue Recognition Monitoring Pipeline",
            "description": "Establish continuous EDGAR â†’ Kafka â†’ River + CapyMOA â†’ Dashboard pipeline with automatic retraining on drift events and periodic compliance reporting.",
            "delivered": "âœ… Complete end-to-end pipeline with real-time dashboard visualization"
        }
    ]
    
    for i, module in enumerate(modules, 1):
        with st.expander(f"{module['title']}", expanded=(i <= 2)):
            st.markdown(f"**Description:** {module['description']}")
            st.markdown(f"**âœ… Delivered:** {module['delivered']}")
    
    # Evaluation Metrics
    st.header("ğŸ“Š Evaluation Metrics")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Text Classification")
        st.markdown("""
        - **Accuracy**: âœ… Tracked in real-time
        - **F1-Score**: âœ… Tracked in real-time
        - **Confusion Matrix**: âœ… Maintained
        """)
        
        st.subheader("Regression / Ratio Analysis")
        st.markdown("""
        - **MAE (Mean Absolute Error)**: âœ… Tracked
        - **RMSE (Root Mean Squared Error)**: âœ… Tracked
        - **RÂ² (Coefficient of Determination)**: âœ… Tracked
        """)
    
    with col2:
        st.subheader("Drift Detection")
        st.markdown("""
        - **Detection Delay**: âœ… Tracked via timestamps
        - **Frequency**: âœ… Number of detections per detector
        """)
        
        st.subheader("Streaming Efficiency")
        st.markdown("""
        - **Throughput (msg/s)**: âœ… Calculable from message counts
        - **Latency**: âœ… Tracked via timestamps
        """)
    
    st.subheader("Cross-Model Agreement")
    st.markdown("""
    - **Consensus Rate (%)**: âœ… Calculated in fusion consumer when multiple detectors agree
    """)
    
    st.subheader("Explainability")
    st.markdown("""
    - **Top-N Keyword Importance**: âœ… Tracked for text features
    - **Feature Importance**: âœ… Tracked for numeric features (rev_to_cash, deferred_ratio)
    """)
    
    # Deliverables
    st.header("âœ… Deliverables Checklist")
    
    deliverables = [
        "âœ… Kafka Ã— River Ã— CapyMOA integrated streaming pipeline (Producer â†’ Consumer â†’ Model â†’ Dashboard)",
        "âœ… Python Jupyter Notebooks for text extraction, preprocessing, and model training",
        "âœ… CapyMOA scripts for drift-aware financial stream analysis",
        "âœ… Combined dataset (revenue_patterns.csv) linking recognition methods to ratios",
        "âœ… Dashboard for real-time anomaly visualization",
        "âœ… Complete documentation and architecture diagrams"
    ]
    
    for item in deliverables:
        st.markdown(f"- {item}")
    
    # Technical Stack
    st.header("ğŸ› ï¸ Technical Stack")
    
    tech_cols = st.columns(3)
    
    with tech_cols[0]:
        st.markdown("""
        **Data Streaming:**
        - Apache Kafka
        - Kafka-Python
        """)
    
    with tech_cols[1]:
        st.markdown("""
        **Machine Learning:**
        - River (Online ML)
        - Scikit-learn
        """)
    
    with tech_cols[2]:
        st.markdown("""
        **Visualization:**
        - Streamlit
        - Pandas
        - Matplotlib
        """)
    
    # How to Run
    st.header("ğŸš€ How to Run")
    
    st.markdown("""
    ### Prerequisites
    1. Kafka installed and running
    2. Python 3.9+ with virtual environment
    3. All dependencies installed (`pip install -r requirements.txt`)
    
    ### Quick Start
    ```bash
    # Terminal 1: Drift Detector
    python3 scripts/capy_drift.py
    
    # Terminal 2: Enhanced Consumers
    python3 scripts/kafka_consumer_river_enhanced.py
    
    # Terminal 3: Producer
    python3 scripts/kafka_producer.py --csv datasets/revenue_patterns_sample.csv --interval 1.0
    
    # Terminal 4: Dashboard
    streamlit run scripts/dashboard_app.py
    ```
    """)
    
    # Key Features
    st.header("ğŸŒŸ Key Features")
    
    features = [
        "ğŸ”„ Real-time streaming processing with Kafka",
        "ğŸ¤– Multiple ML models (3 text classifiers, 2 regression models)",
        "ğŸ“ˆ 5 different drift detectors (ADWIN, DDM, EDDM, KSWIN, PageHinkley)",
        "ğŸ”— Cross-platform fusion combining River and CapyMOA outputs",
        "ğŸ“Š Feature importance tracking for explainability",
        "ğŸ“‰ Comprehensive evaluation metrics in real-time",
        "ğŸ¨ Interactive real-time dashboard",
        "ğŸ“š Incremental online learning"
    ]
    
    for feature in features:
        st.markdown(f"- {feature}")
    
    # Footer
    st.markdown("---")
    st.markdown("**Group 16 - FDA-3-Stream Project** | Big Data Analytics Assignment")

